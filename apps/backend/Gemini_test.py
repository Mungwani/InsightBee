import os
import warnings
from typing import List, Dict, Tuple

import google.generativeai as genai
import pandas as pd
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer, util
from tqdm import tqdm
from tqdm.auto import tqdm as auto_tqdm # pandas.apply ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•¨

# --- 1. ì„¤ì • (Configuration) ---
INPUT_FILENAME = "news_test.csv"
OUTPUT_FILENAME = "news_classified_results_representatives2.csv"
EMBEDDING_MODEL_NAME = 'distiluse-base-multilingual-cased-v1'
GEMINI_MODEL_NAME = 'gemini-2.5-flash' # ë˜ëŠ” 'gemini-1.0-pro' ë“± ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸
TOPIC_CATEGORIES = [
    "ì‹ ì‚¬ì—…/M&A", "ê²½ì˜ì „ëµ/ë¦¬ë”ì‹­", "í•´ì™¸ì§„ì¶œ/ê¸€ë¡œë²Œ ë™í–¥", "íˆ¬ììœ ì¹˜/ì¬ë¬´", "ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ",
    "ê¸°ìˆ ê°œë°œ/R&D", "ìƒì‚°/ê³µê¸‰ë§ ê´€ë¦¬", "íŠ¹í—ˆ/ê¸°ìˆ ì¸ì¦", "ì‹œì¥ë™í–¥/íŠ¸ë Œë“œ ë¶„ì„", "ê²½ìŸì‚¬ ë™í–¥",
    "ì •ë¶€ê·œì œ/ì •ì±…", "ì¸ì¬ì±„ìš©/ì¸ì¬ìƒ", "ì¡°ì§ë¬¸í™”/ì¸ì‚¬ì œë„", "ì„ì§ì› ë™ì •/ì¸ì‚¬", "ë…¸ì‚¬ê´€ê³„/ê³ ìš©ì´ìŠˆ",
    "ESG/ì§€ì†ê°€ëŠ¥ê²½ì˜", "ì‚¬íšŒê³µí—Œ/CSR", "ì†Œë¹„ìë³´í˜¸/ë¶„ìŸ", "íŒŒíŠ¸ë„ˆì‹­/í˜‘ë ¥", "ëŒ€ì™¸í™œë™/í™ë³´", "ë¦¬ìŠ¤í¬/ìœ„ê¸°ê´€ë¦¬"
]

def setup_gemini() -> genai.GenerativeModel:
    """API í‚¤ë¥¼ ì„¤ì •í•˜ê³  Gemini ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    load_dotenv()
    warnings.filterwarnings("ignore")
    auto_tqdm.pandas(desc="ê°œë³„ ê¸°ì‚¬ ë¶„ì„(ìš”ì•½+ë¶„ë¥˜) ì¤‘") # tqdm.pandas() í™œì„±í™”
    try:
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("'.env' íŒŒì¼ì—ì„œ GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=api_key)
        print("âœ… Gemini API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        print(f"âŒ API í‚¤ ë˜ëŠ” ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

def load_and_preprocess_data(filepath: str) -> pd.DataFrame:
    """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¶„ì„ì— ë§ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    print(f"\n1ë‹¨ê³„: '{filepath}' íŒŒì¼ ë¡œë”© ë° ì „ì²˜ë¦¬...")
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{filepath}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    df.columns = df.columns.str.strip()
    if 'ë³¸ë¬¸' in df.columns: df.rename(columns={'ë³¸ë¬¸': 'content'}, inplace=True)
    if 'ì œëª©' in df.columns: df.rename(columns={'ì œëª©': 'title'}, inplace=True)
    df.dropna(subset=['title', 'content'], inplace=True)
    df.drop_duplicates(subset=['title'], keep='first', inplace=True)
    df.reset_index(drop=True, inplace=True)
    print(f"âœ… ì´ {len(df)}ê°œì˜ ê³ ìœ í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")
    return df

def cluster_articles(df: pd.DataFrame) -> pd.DataFrame:
    """SentenceTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ 'ê±°ì˜ ë™ì¼í•œ' ê¸°ì‚¬ë“¤ì„ ê·¸ë£¹í™”í•©ë‹ˆë‹¤."""
    print(f"\n2ë‹¨ê³„: '{EMBEDDING_MODEL_NAME}' ëª¨ë¸ë¡œ ì¤‘ë³µ ê¸°ì‚¬ ê·¸ë£¹í™”...")
    model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    embeddings = model.encode(df['content'].tolist(), show_progress_bar=True)
    
    # [í•µì‹¬] 'ê±°ì˜ ë™ì¼í•œ ì´ë²¤íŠ¸'ë¥¼ ë¬¶ë„ë¡ ê¸°ì¤€ì„ ìƒí–¥ (threshold=0.8)
    clusters = util.community_detection(embeddings, min_community_size=2, threshold=0.8)
    
    doc_id_to_cluster_id = {doc_id: i for i, cluster in enumerate(clusters) for doc_id in cluster}
    
    df['cluster_id'] = df.index.map(lambda x: doc_id_to_cluster_id.get(x, -1))
    print(f"âœ… {len(clusters)}ê°œì˜ ê³ ìœ í•œ ì´ë²¤íŠ¸(ì¤‘ë³µ ê·¸ë£¹)ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    return df

# [ì‹ ê·œ] 3ë‹¨ê³„: ê°œë³„ ê¸°ì‚¬ ë¶„ì„ (ìš”ì•½ + ë¶„ë¥˜)
def get_summary_and_topic(content: str, model: genai.GenerativeModel, categories: List[str]) -> Tuple[str, str]:
    """
    ë‹¨ì¼ ê¸°ì‚¬ ë³¸ë¬¸ì„ ë°›ì•„, [ìš”ì•½]ê³¼ [í† í”½]ì„ í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    category_list_str = f"[{', '.join(categories)}]"
    
    # [í”„ë¡¬í”„íŠ¸ ê³ ë„í™”] ìš”ì•½ê³¼ ë¶„ë¥˜ë¥¼ í•œ ë²ˆì— ìš”ì²­
    prompt = (
        f"ë‹¹ì‹ ì€ ì·¨ì—… ì¤€ë¹„ìƒì˜ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë•ëŠ” ì „ë¬¸ ì»¤ë¦¬ì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
        f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ê³ , 2ê°€ì§€ ì„ë¬´ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.\n\n"
        f"1. **[ì˜ë¯¸ ìš”ì•½]**: ì´ ë‰´ìŠ¤ê°€ ì§€ì›ìì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€(ì„±ì¥ ë™ë ¥, ìœ„ê¸°, ì¸ì¬ìƒ ë“±)ì— ì´ˆì ì„ ë§ì¶° 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n"
        f"2. **[í† í”½ ë¶„ë¥˜]**: ì£¼ì–´ì§„ 'í† í”½ ëª©ë¡'ì—ì„œ ì´ ê¸°ì‚¬ì˜ í•µì‹¬ ì£¼ì œì™€ ê°€ì¥ ì í•©í•œ ì¹´í…Œë¦¬ í•˜ë‚˜ë§Œì„ ì„ íƒí•©ë‹ˆë‹¤.\n\n"
        f"--- í† í”½ ëª©ë¡ ---\n{category_list_str}\n\n"
        f"--- ê¸°ì‚¬ ë³¸ë¬¸ ---\n{content}\n\n"
        f"--- [ì¤‘ìš”] ì‘ë‹µ í˜•ì‹ ---\n"
        f"ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):\n"
        f"ìš”ì•½: [ì—¬ê¸°ì— 1ë²ˆ ì„ë¬´ì˜ ìš”ì•½ ë‚´ìš©ì„ ì‘ì„±]\n"
        f"í† í”½: [ì—¬ê¸°ì— 2ë²ˆ ì„ë¬´ì˜ í† í”½ì„ ì‘ì„±]"
    )
    
    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        # [ì‘ë‹µ íŒŒì‹±] "ìš”ì•½:", "í† í”½:"ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¦¬
        summary_part = "ìš”ì•½ ì‹¤íŒ¨"
        topic_part = "ë¶„ë¥˜ ì‹¤íŒ¨"
        
        if "ìš”ì•½:" in text and "í† í”½:" in text:
            summary_raw = text.split("ìš”ì•½:")[1].split("í† í”½:")[0].strip()
            topic_raw = text.split("í† í”½:")[1].strip()
            
            summary_part = summary_raw
            # í† í”½ ëª©ë¡ì— ìˆëŠ” ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ì¸ì§€ í•œë²ˆ ë” í™•ì¸
            topic_part = next((cat for cat in categories if cat in topic_raw), "ë¶„ë¥˜ ì‹¤íŒ¨")
        else:
            # ì˜ˆì™¸: í˜•ì‹ì„ ì§€í‚¤ì§€ ì•Šì€ ì‘ë‹µ
            summary_part = text[:150] + "..." # ì‘ë‹µì˜ ì¼ë¶€ë¼ë„ ì €ì¥
            
        return summary_part, topic_part
    
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", f"ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    gemini_model = setup_gemini()
    df = load_and_preprocess_data(INPUT_FILENAME)
    df_clustered = cluster_articles(df)
    
    # --- ì¤‘ë³µ ê¸°ì‚¬ ì œê±° ë° ëŒ€í‘œ ê¸°ì‚¬ ì„ ì • ---
    print("\nì¤‘ê°„ ë‹¨ê³„: ê° ê·¸ë£¹ë³„ ëŒ€í‘œ ê¸°ì‚¬ 1ê°œì”© ì„ ì •...")
    df_representatives = df_clustered[df_clustered['cluster_id'] != -1].drop_duplicates(subset=['cluster_id'], keep='first')
    df_others = df_clustered[df_clustered['cluster_id'] == -1]
    df_filtered = pd.concat([df_representatives, df_others]).sort_index()
    
    print(f"âœ… 'ê¸°íƒ€'(ê³ ìœ ) ê¸°ì‚¬ {len(df_others)}ê°œì™€ 'ëŒ€í‘œ' ê¸°ì‚¬ {len(df_representatives)}ê°œë¥¼ í¬í•¨, ì´ {len(df_filtered)}ê°œë¡œ ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # --- ë¡œì§ ë ---

    
    # --- [ì‹ ê·œ] 3ë‹¨ê³„: ì••ì¶•ëœ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ê°œë³„ ë¶„ì„ (ìš”ì•½ + ë¶„ë¥˜) ì‹¤í–‰ ---
    print(f"\n3ë‹¨ê³„: Gemini APIë¡œ {len(df_filtered)}ê°œì˜ ê³ ìœ /ëŒ€í‘œ ê¸°ì‚¬ ë¶„ì„ ì‹œì‘...")
    
    # .progress_apply()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  í‘œì‹œì¤„ê³¼ í•¨ê»˜ ëª¨ë“  í–‰ì— í•¨ìˆ˜ ì ìš©
    # ì´ í•¨ìˆ˜ëŠ” (summary, topic) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    results = df_filtered['content'].progress_apply(
        lambda x: get_summary_and_topic(x, gemini_model, TOPIC_CATEGORIES)
    )

    # íŠœí”Œë¡œ ë°˜í™˜ëœ ê²°ê³¼ë¥¼ ë‘ ê°œì˜ ìƒˆë¡œìš´ ì—´('summary', 'topic')ë¡œ ë¶„ë¦¬
    df_final = df_filtered.copy()
    df_final['summary'] = results.apply(lambda x: x[0])
    df_final['topic'] = results.apply(lambda x: x[1])
    
    df_final.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ê°€ '{OUTPUT_FILENAME}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\n--- ìµœì¢… í† í”½ ë¶„ë¥˜ ìš”ì•½ ---")
    print(df_final['topic'].value_counts())

if __name__ == "__main__":
    main()