import os
import warnings
from typing import List, Dict

import google.generativeai as genai
import pandas as pd
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer, util
from tqdm import tqdm
from tqdm.auto import tqdm as auto_tqdm # pandas.apply ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•¨

# --- 1. ì„¤ì • (Configuration) ---
INPUT_FILENAME = "news_test.csv"
OUTPUT_FILENAME = "news_classified_results_summary_individual.csv"
EMBEDDING_MODEL_NAME = 'distiluse-base-multilingual-cased-v1'
GEMINI_MODEL_NAME = 'gemini-2.5-flash' # ë˜ëŠ” 'gemini-1.0-pro' ë“± ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸
TOPIC_CATEGORIES = [
    "ì‹ ì‚¬ì—…/M&A", "ê²½ì˜ì „ëµ/ë¦¬ë”ì‹­", "í•´ì™¸ì§„ì¶œ/ê¸€ë¡œë²Œ ë™í–¥", "íˆ¬ììœ ì¹˜/ì¬ë¬´", "ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ",
    "ê¸°ìˆ ê°œë°œ/R&D", "ìƒì‚°/ê³µê¸‰ë§ ê´€ë¦¬", "íŠ¹í—ˆ/ê¸°ìˆ ì¸ì¦", "ì‹œì¥ë™í–¥/íŠ¸ë Œë“œ ë¶„ì„", "ê²½ìŸì‚¬ ë™í–¥",
    "ì •ë¶€ê·œì œ/ì •ì±…", "ì¸ì¬ì±„ìš©/ì¸ì¬ìƒ", "ì¡°ì§ë¬¸í™”/ì¸ì‚¬ì œë„", "ì„ì§ì› ë™ì •/ì¸ì‚¬", "ë…¸ì‚¬ê´€ê³„/ê³ ìš©ì´ìŠˆ",
    "ESG/ì§€ì†ê°€ëŠ¥ê²½ì˜", "ì‚¬íšŒê³µí—Œ/CSR", "ì†Œë¹„ìë³´í˜¸/ë¶„ìŸ", "íŒŒíŠ¸ë„ˆì‹­/í˜‘ë ¥", "ëŒ€ì™¸í™œë™/í™ë³´", "ë¦¬ìŠ¤í¬/ìœ„ê¸°ê´€ë¦¬"
]

def setup_gemini() -> genai.GenerativeModel:
    """API í‚¤ë¥¼ ì„¤ì •í•˜ê³  Gemini ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    load_dotenv()
    warnings.filterwarnings("ignore")
    auto_tqdm.pandas(desc="ê°œë³„ ê¸°ì‚¬ ìš”ì•½ ì¤‘") # tqdm.pandas() í™œì„±í™”
    try:
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("'.env' íŒŒì¼ì—ì„œ GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=api_key)
        print("âœ… Gemini API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        print(f"âŒ API í‚¤ ë˜ëŠ” ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

def load_and_preprocess_data(filepath: str) -> pd.DataFrame:
    """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¶„ì„ì— ë§ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    print(f"\n1ë‹¨ê³„: '{filepath}' íŒŒì¼ ë¡œë”© ë° ì „ì²˜ë¦¬...")
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{filepath}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    df.columns = df.columns.str.strip()
    if 'ë³¸ë¬¸' in df.columns: df.rename(columns={'ë³¸ë¬¸': 'content'}, inplace=True)
    if 'ì œëª©' in df.columns: df.rename(columns={'ì œëª©': 'title'}, inplace=True)
    df.dropna(subset=['title', 'content'], inplace=True)
    df.drop_duplicates(subset=['title'], keep='first', inplace=True)
    df.reset_index(drop=True, inplace=True) # ê·¸ë£¹í™”ë¥¼ ìœ„í•´ ì¸ë±ìŠ¤ ì¬ì„¤ì •
    print(f"âœ… ì´ {len(df)}ê°œì˜ ê³ ìœ í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")
    return df

def cluster_articles(df: pd.DataFrame) -> pd.DataFrame:
    """SentenceTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ë“¤ì„ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤."""
    print(f"\n2ë‹¨ê³„: '{EMBEDDING_MODEL_NAME}' ëª¨ë¸ë¡œ ê¸°ì‚¬ ê·¸ë£¹í™”...")
    model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    embeddings = model.encode(df['content'].tolist(), show_progress_bar=True)
    
    clusters = util.community_detection(embeddings, min_community_size=3, threshold=0.5)
    
    doc_id_to_cluster_id = {doc_id: i for i, cluster in enumerate(clusters) for doc_id in cluster}
    
    df['cluster_id'] = df.index.map(lambda x: doc_id_to_cluster_id.get(x, -1))
    print(f"âœ… {len(clusters)}ê°œì˜ ì˜ë¯¸ ìˆëŠ” ê·¸ë£¹ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    return df

# [ìˆ˜ì •] 3ë‹¨ê³„: í† í”½ ë¶„ë¥˜ (í”„ë¡¬í”„íŠ¸ ê³ ë„í™”)
def classify_clusters(df: pd.DataFrame, model: genai.GenerativeModel, categories: List[str]) -> Dict[int, str]:
    """ê·¸ë£¹í™”ëœ ê¸°ì‚¬ë“¤ì„ Gemini APIë¥¼ í†µí•´ ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    print("\n3ë‹¨ê³„: Gemini APIë¡œ ê° ê·¸ë£¹ì˜ í† í”½ ë¶„ë¥˜...")
    topic_map = {}
    
    valid_clusters = [c for c in df['cluster_id'].unique() if c != -1]

    for cluster_id in tqdm(valid_clusters, desc="ê·¸ë£¹ í† í”½ ë¶„ë¥˜ ì¤‘"):
        try:
            cluster_df = df[df['cluster_id'] == cluster_id]
            sample_titles = cluster_df.head(5)['title'].tolist()
            titles_str = "\n".join([f"- {title}" for title in sample_titles])

            category_list_str = f"[{', '.join(categories)}]"
            
            # [í”„ë¡¬í”„íŠ¸ ê³ ë„í™”] ì·¨ì—…ì¤€ë¹„ìƒì„ ìœ„í•œ í˜ë¥´ì†Œë‚˜ ë° ëª©ì  ë¶€ì—¬
            classification_prompt = (
                f"ë‹¹ì‹ ì€ ì·¨ì—… ì¤€ë¹„ìƒì˜ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë•ëŠ” ì „ë¬¸ ì»¤ë¦¬ì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
                f"ì•„ë˜ëŠ” ì§€ì›ìê°€ ê´€ì‹¬ ìˆëŠ” ê¸°ì—…ì˜ ìµœì‹  ë‰´ìŠ¤ ì œëª©ë“¤ì…ë‹ˆë‹¤. "
                f"ì´ ê¸°ì‚¬ë“¤ì˜ í•µì‹¬ ì£¼ì œë¥¼ íŒŒì•…í•˜ì—¬, ì§€ì›ìê°€ ìê¸°ì†Œê°œì„œë‚˜ ë©´ì ‘ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ "
                f"ì£¼ì–´ì§„ 'ì§ë¬´/ì‚°ì—… í† í”½ ëª©ë¡'ì—ì„œ ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.\n\n"
                f"ëŒ€ë‹µì€ ëª¨ë‘ ì¡´ëŒ“ë§ë¡œ í•©ë‹ˆë‹¤.\n\n"
                f"--- ì§ë¬´/ì‚°ì—… í† í”½ ëª©ë¡ ---\n{category_list_str}\n\n"
                f"--- ê¸°ì‚¬ ì œëª© ëª©ë¡ ---\n{titles_str}\n\n"
                f"ê°€ì¥ ì í•©í•œ í† í”½ (ëª©ë¡ì—ì„œ í•˜ë‚˜ë§Œ ì„ íƒ): "
            )
            
            classification_response = model.generate_content(classification_prompt)
            found_category = next((cat for cat in categories if cat in classification_response.text), "ë¶„ë¥˜ ì‹¤íŒ¨")
            topic_map[cluster_id] = found_category

        except Exception as e:
            print(f"  - í´ëŸ¬ìŠ¤í„° {cluster_id} ì²˜ë¦¬ ì¤‘ API ì˜¤ë¥˜: {e}")
            topic_map[cluster_id] = "API ì˜¤ë¥˜"
            
    return topic_map

# [ì‹ ê·œ] 4ë‹¨ê³„: ê°œë³„ ê¸°ì‚¬ ìš”ì•½
def generate_individual_summaries(df: pd.DataFrame, model: genai.GenerativeModel) -> pd.DataFrame:
    """
    ëª¨ë“  ê°œë³„ ê¸°ì‚¬ì— ëŒ€í•´ ê³ ìœ í•œ ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    [ì£¼ì˜] ì´ í•¨ìˆ˜ëŠ” ê¸°ì‚¬ Nê°œì— ëŒ€í•´ Në²ˆì˜ API í˜¸ì¶œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"\n4ë‹¨ê³„: Gemini APIë¡œ {len(df)}ê°œì˜ ê°œë³„ ê¸°ì‚¬ ìš”ì•½ ìƒì„±...")
    
    def get_summary(content: str) -> str:
        """ë‹¨ì¼ ê¸°ì‚¬ ë³¸ë¬¸ì„ ë°›ì•„ ìš”ì•½ë¬¸ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
        try:
            # [í”„ë¡¬í”„íŠ¸ ê³ ë„í™”] ì·¨ì—…ì¤€ë¹„ìƒì„ ìœ„í•œ 'So What' ê´€ì ì˜ ìš”ì•½ ì§€ì‹œ
            summary_prompt = (
                f"ë‹¹ì‹ ì€ ì·¨ì—… ì¤€ë¹„ìƒì˜ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë•ëŠ” ì „ë¬¸ ì»¤ë¦¬ì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
                f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ê³ , ì´ ë‰´ìŠ¤ê°€ ì§€ì›ìì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€(ì˜ˆ: íšŒì‚¬ì˜ ì„±ì¥ ë™ë ¥, ì§ë©´í•œ ìœ„ê¸°, ì¸ì¬ìƒ ë³€í™” ë“±)ì— ì´ˆì ì„ ë§ì¶° "
                f"í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n"
                f"ëŒ€ë‹µì€ ëª¨ë‘ ì¡´ëŒ“ë§ë¡œ í•©ë‹ˆë‹¤.\n\n"
                f"**[ì¤‘ìš” ì§€ì‹œ] ì‘ë‹µì€ ì–´ë– í•œ ë¨¸ë¦¬ë§, ì¸ì‚¬, ë˜ëŠ” 'ìš”ì•½:'ê³¼ ê°™ì€ ì ‘ë‘ì‚¬ë„ ë¶™ì´ì§€ ë§ê³ , ìˆœìˆ˜í•œ 2-3ë¬¸ì¥ì˜ ìš”ì•½ ë‚´ìš©ìœ¼ë¡œ ì¦‰ì‹œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.**\n\n"
                f"--- ê¸°ì‚¬ ë³¸ë¬¸ ---\n{content}\n\n"
                f"ìš”ì•½:"
            )
            response = model.generate_content(summary_prompt)
            return response.text.strip()
        except Exception as e:
            return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    # .progress_apply()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  í‘œì‹œì¤„ê³¼ í•¨ê»˜ ëª¨ë“  í–‰ì— í•¨ìˆ˜ ì ìš©
    df['summary'] = df['content'].progress_apply(get_summary)
    return df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    gemini_model = setup_gemini()
    df = load_and_preprocess_data(INPUT_FILENAME)
    df_clustered = cluster_articles(df)
    
    # 3ë‹¨ê³„: í† í”½ ë¶„ë¥˜
    topic_map = classify_clusters(df_clustered, gemini_model, TOPIC_CATEGORIES)
    df_clustered['topic'] = df_clustered['cluster_id'].map(topic_map).fillna('ê¸°íƒ€')
    
    # 4ë‹¨ê³„: ê°œë³„ ê¸°ì‚¬ ìš”ì•½
    df_final = generate_individual_summaries(df_clustered, gemini_model)
    
    df_final.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ê°€ '{OUTPUT_FILENAME}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\n--- ìµœì¢… í† í”½ ë¶„ë¥˜ ìš”ì•½ ---")
    print(df_final['topic'].value_counts())

if __name__ == "__main__":
    main()
